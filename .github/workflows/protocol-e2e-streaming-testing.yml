# workflows/protocol-e2e-streaming-testing.yml
#
# Protocol: End-to-End Streaming Testing
# Compute the Protocol Streaming End-to-End benchmarks

name: "Protocol: End-to-End Streaming Testing"

on:
  schedule:
    # Run dev benchmarking once per day on weekdays (days of the week 1-5) at 00:01 UTC.
    - cron: "1 0 * * 1,2,3,4,5"
  pull_request:
    paths:
      - "protocol/**"
      - "!protocol/**/README.md"
      - ".github/workflows/protocol-e2e-streaming-testing.yml"
      - "mandelboxes/scripts/copy_protocol_build.sh"
      - "mandelboxes/development/client/**/"
      - ".github/workflows/helpers/parse_and_display_e2e_results.py"
      - ".github/workflows/helpers/protocol/e2e_streaming_test_display_helpers/**"
  workflow_dispatch:

# This guarantees that if you push many commits to the same PR, only the latest
# commit will get run (others get cancelled)
concurrency:
  group: protocol-e2e-streaming-testing-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  # This job runs a protocol streaming session between two Docker containers on the same
  # AWS EC2 instance to test end-to-end networking performance in a controlled environment.
  protocol-streaming-e2e-check-pr:
    name: "Protocol Streaming End-to-End Test"
    runs-on: ubuntu-20.04
    env:
      CLIENT_INSTANCE_ID: "i-0f198404fc63b3b3f"
      SERVER_INSTANCE_ID: "i-0d215f4e50a4313ff"

    steps:
      - name: Checkout Git Repository
        uses: actions/checkout@v3

      - name: Setup Python-based notifications
        working-directory: .github/workflows/helpers
        run: ./notifications/setup_notifications.sh true

      - name: Configure AWS S3 CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_GITHUB_ACTIONS_USER_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_GITHUB_ACTIONS_USER_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      # Load the AWS SSH keypair onto the runner, so that it can run remote commands on the AWS EC2 machine
      # running the streaming end-to-end test. This keypair is defined in AWS and stored as a GitHub Secret.
      - name: Install SSH key
        uses: shimataro/ssh-key-action@v2
        with:
          name: id_rsa
          key: ${{ secrets.PROTOCOL_E2E_SREAMING_TEST_INSTANCE_SSH_KEY }}
          known_hosts: unnecessary # Note, this is not secure and discouraged, but tolerable here given the instance is deleted after the test
          if_key_exists: fail

      - name: Print Github Context for debugging purposes
        run: echo "$GITHUB_CONTEXT"

      # Steps to detect branch acknowledged to https://stackoverflow.com/questions/58033366/how-to-get-the-current-branch-within-github-actions
      - name: Get branch name and commit SHA
        if: always()
        run: |
          if [[ ${{ github.event_name }} == 'pull_request' ]]; then
            echo "BRANCH_NAME=$(echo ${GITHUB_HEAD_REF})" >> $GITHUB_ENV
            echo "GITHUB_COMMIT_HASH=$(echo ${{ github.event.after }})" >> $GITHUB_ENV
          else
            echo "BRANCH_NAME=$(echo ${GITHUB_REF#refs/heads/})" >> $GITHUB_ENV
            echo "GITHUB_COMMIT_HASH=$(echo ${GITHUB_SHA})" >> $GITHUB_ENV
          fi

      - name: Install End-to-End Streaming Test Dependencies
        run: pip install boto3 paramiko numpy pytablewriter

      # Prevent two instances of this workflow from running the steps below simultaneously
      - name: Turnstyle
        uses: rpadaki/turnstyle@v1.1
        with:
          same-branch-only: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Run the streaming end-to-end integration test. The -ssh-key-name must match the value in AWS EC2 under
      # Key Pairs, where the SSH key is defined. Other possible flags:
      # --testing_url, defaults to Big Buck Bunny video stored on our AWS S3
      # --testing_time, defaults to 126s
      # --cmake-build-type, defaults to `Metrics`
      # --region-name, defaults to `us-east-1`
      # --use-two-instances, defaults to `false`
      # --use-existing-server-instance, defaults to `` (empty string)
      # --use-existing-client-instance, defaults to `` (empty string)
      # --aws-credentials-filepath, defaults to `~/.aws/credentials`
      # --network-conditions [bandwidth range],[packet delay range],[packet drop range],[qdisc packet limit range],[interval of change range]

      ### Action below will run the End-to-End Streaming Test for each new commit to a branch of a PR. ###
      - name: Run End-to-End Streaming Test (S3 video playout - ideal network conditions)
        id: e2e_streaming_test0
        working-directory: protocol/test
        run: |
          python3 streaming_e2e_tester.py \
            --ssh-key-name "GITHUB_ACTIONS_E2E_PERFORMANCE_TEST_SSH_KEYPAIR" \
            --ssh-key-path "/home/runner/.ssh/id_rsa" \
            --github-token "${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}" \
            --use-two-instances=true \
            --use-existing-client-instance "$CLIENT_INSTANCE_ID" \
            --use-existing-server-instance "$SERVER_INSTANCE_ID" \
            --leave-instances-on=true
          # Update SERVER_INSTANCE_ID and CLIENT_INSTANCE_ID variables in case we had to create new instances. We will reuse them in the next step.
          echo "SERVER_INSTANCE_ID=$(head -n 1 instances_left_on.txt)" >> $GITHUB_ENV
          echo "CLIENT_INSTANCE_ID=$(tail -n 1 instances_left_on.txt)" >> $GITHUB_ENV

      - name: Run End-to-End Streaming Test (S3 video playout - good network)
        id: e2e_streaming_test1
        working-directory: protocol/test
        run: |
          python3 streaming_e2e_tester.py \
            --ssh-key-name "GITHUB_ACTIONS_E2E_PERFORMANCE_TEST_SSH_KEYPAIR" \
            --ssh-key-path "/home/runner/.ssh/id_rsa" \
            --github-token "${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}" \
            --use-two-instances=true \
            --use-existing-client-instance "$CLIENT_INSTANCE_ID" \
            --use-existing-server-instance "$SERVER_INSTANCE_ID" \
            --leave-instances-on=true \
            --skip-host-setup=true \
            --skip-git-clone=true \
            --network-conditions 15Mbit-30Mbit,10,None,None,1000-2000
          # Update SERVER_INSTANCE_ID and CLIENT_INSTANCE_ID variables in case we had to create new instances. We will reuse them in the next step.
          echo "SERVER_INSTANCE_ID=$(head -n 1 instances_left_on.txt)" >> $GITHUB_ENV
          echo "CLIENT_INSTANCE_ID=$(tail -n 1 instances_left_on.txt)" >> $GITHUB_ENV

      - name: Run End-to-End Streaming Test (S3 video playout - busy network)
        id: e2e_streaming_test2
        working-directory: protocol/test
        run: |
          python3 streaming_e2e_tester.py \
            --ssh-key-name "GITHUB_ACTIONS_E2E_PERFORMANCE_TEST_SSH_KEYPAIR" \
            --ssh-key-path "/home/runner/.ssh/id_rsa" \
            --github-token "${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}" \
            --use-two-instances=true \
            --use-existing-client-instance "$CLIENT_INSTANCE_ID" \
            --use-existing-server-instance "$SERVER_INSTANCE_ID" \
            --leave-instances-on=true \
            --skip-host-setup=true \
            --skip-git-clone=true \
            --network-conditions 10Mbit-20Mbit,10,None,None,100-1000
          # Update SERVER_INSTANCE_ID and CLIENT_INSTANCE_ID variables in case we had to create new instances. We will reuse them in the next step.
          echo "SERVER_INSTANCE_ID=$(head -n 1 instances_left_on.txt)" >> $GITHUB_ENV
          echo "CLIENT_INSTANCE_ID=$(tail -n 1 instances_left_on.txt)" >> $GITHUB_ENV

      - name: Run End-to-End Streaming Test (S3 video playout - low bandwidth 10 Mbps network)
        id: e2e_streaming_test3
        working-directory: protocol/test
        run: |
          python3 streaming_e2e_tester.py \
            --ssh-key-name "GITHUB_ACTIONS_E2E_PERFORMANCE_TEST_SSH_KEYPAIR" \
            --ssh-key-path "/home/runner/.ssh/id_rsa" \
            --github-token "${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}" \
            --use-two-instances=true \
            --use-existing-client-instance "$CLIENT_INSTANCE_ID" \
            --use-existing-server-instance "$SERVER_INSTANCE_ID" \
            --leave-instances-on=true \
            --skip-host-setup=true \
            --skip-git-clone=true \
            --network-conditions 10Mbit,10,None,100,None
          # Update SERVER_INSTANCE_ID and CLIENT_INSTANCE_ID variables in case we had to create new instances. We will reuse them in the next step.
          echo "SERVER_INSTANCE_ID=$(head -n 1 instances_left_on.txt)" >> $GITHUB_ENV
          echo "CLIENT_INSTANCE_ID=$(tail -n 1 instances_left_on.txt)" >> $GITHUB_ENV

      - name: Run End-to-End Streaming Test (Aggressive text scrolling - low bandwidth 10 Mbps network)
        id: e2e_streaming_test4
        working-directory: protocol/test
        run: |
          python3 streaming_e2e_tester.py \
            --ssh-key-name "GITHUB_ACTIONS_E2E_PERFORMANCE_TEST_SSH_KEYPAIR" \
            --ssh-key-path "/home/runner/.ssh/id_rsa" \
            --github-token "${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}" \
            --use-two-instances=true \
            --use-existing-client-instance "$CLIENT_INSTANCE_ID" \
            --use-existing-server-instance "$SERVER_INSTANCE_ID" \
            --leave-instances-on=false \
            --skip-host-setup=true \
            --skip-git-clone=true \
            --testing-url="https://docs.nvidia.com/video-technologies/video-codec-sdk/nvenc-video-encoder-api-prog-guide/" \
            --simulate-scrolling 10 \
            --network-conditions 10Mbit,10,None,100,None
          # Update SERVER_INSTANCE_ID and CLIENT_INSTANCE_ID variables in case we had to create new instances. We will reuse them in the next step.
          echo "SERVER_INSTANCE_ID=$(head -n 1 instances_left_on.txt)" >> $GITHUB_ENV
          echo "CLIENT_INSTANCE_ID=$(tail -n 1 instances_left_on.txt)" >> $GITHUB_ENV

      # need one more section like this to ensure the S3 command works in case of failure/timeout of the Python script above
      - name: Upload logs to S3 for debugging purposes
        if: always()
        working-directory: protocol/test
        run: |
          aws s3 cp perf_logs s3://whist-e2e-protocol-test-logs/"${{ env.BRANCH_NAME }}" --recursive
          echo ""; echo "Download S3 logs with the following commands:"
          cd perf_logs; for dir in */; do echo "aws s3 cp s3://whist-e2e-protocol-test-logs/${{ env.BRANCH_NAME }}/$dir $dir --recursive"; done

      - name: Stop or terminate leftover AWS instances
        if: always()
        working-directory: protocol/test
        run: python3 -m helpers.aws.remove_leftover_instances

      # We parse the log files from the E2E performance tests above and display the results of the test.
      # We compare the performance to dev and the previous runs of the same branch, if available
      - name: Parse & Display Test Results
        if: always()
        working-directory: protocol/test
        env:
          GITHUB_GIST_TOKEN: ${{ secrets.GHA_PERSONAL_ACCESS_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_ISSUE: ${{ github.event.number }}
          GITHUB_PR_URL: "https://github.com/whisthq/whist/pull/"
          SLACK_WEBHOOK: ${{ secrets.SLACK_HOOKS_ENDPOINT_DEV }}
        run: |
          python3 ../../.github/workflows/helpers/parse_and_display_e2e_results.py \
            --compared-branch-name "dev" "${{ env.BRANCH_NAME }}" \
            --e2e-script-outcomes "${{ steps.e2e_streaming_test0.outcome }}" "${{ steps.e2e_streaming_test1.outcome }}" "${{ steps.e2e_streaming_test2.outcome }}" "${{ steps.e2e_streaming_test3.outcome }}" \
            "${{ steps.e2e_streaming_test4.outcome }}" --post-results-on-slack="${{ github.event_name == 'schedule' }}"

  #######################################################################################
